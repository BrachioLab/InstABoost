{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0ad61b-79a5-466e-80df-6bcdb0af08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96363cbc-ccf6-4864-9c49-3d6036d01b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'Meta-Llama-3-8B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ca7925-9b15-4040-aff0-9afa578b2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_emotions = '../results/emotions'\n",
    "base_path_ai_persona = '../results/ai-risk'\n",
    "base_path_truth = '../results/truthfulqa'\n",
    "base_path_trivia = '../results/triviaqa'\n",
    "base_path_safety = '../results/safety'\n",
    "base_path_jbb = '../results/jbb'\n",
    "base_path_toxicity = '../results/toxicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14506ecf-81c2-48b6-a683-0f34da0694bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f694f39a-d5c4-4f53-acf2-7e1a2107937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "emo_results = {}\n",
    "for emotion in emotions:\n",
    "    emo_results[emotion] = {}\n",
    "    res_path = os.path.join(base_path_emotions, \n",
    "                   f\"{emotion}/{model}/all_methods_results.json\")\n",
    "    if os.path.exists(res_path):\n",
    "        with open(res_path, 'r') as f:\n",
    "            res = json.load(f)\n",
    "    emo_results[emotion] = res['methods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6134b6ec-d5e9-46bf-a76c-41b7e6006569",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['mcq', 'qa']\n",
    "behaviors = ['power', 'wealth']\n",
    "risk_results = {}\n",
    "for t in types:\n",
    "    for b in behaviors:\n",
    "        b_name = b + '-' + t\n",
    "        risk_results[b_name] = {}\n",
    "        res_path = os.path.join(base_path_ai_persona+'-'+t, \n",
    "                       f\"{b}/{model}/all_methods_results.json\")\n",
    "        if os.path.exists(res_path):\n",
    "            with open(res_path, 'r') as f:\n",
    "                res = json.load(f)\n",
    "        risk_results[b_name] = res['methods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0343a16c-90ad-46e7-b3bd-506e9a65604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_single(base_path,  \n",
    "                       model='Meta-Llama-3-8B-Instruct', flip_t_f = False):\n",
    "    results = {}\n",
    "    res_path = os.path.join(base_path, \n",
    "                   f\"{model}/all_methods_results.json\")\n",
    "    if os.path.exists(res_path):\n",
    "        with open(res_path, 'r') as f:\n",
    "            res = json.load(f)\n",
    "        results = res['methods']\n",
    "        if flip_t_f:\n",
    "            for method in results.keys():\n",
    "                results[method]['score'] = 1-results[method]['score']\n",
    "                low = results[method]['score_ci']['lower']\n",
    "                upp = results[method]['score_ci']['upper']\n",
    "                results[method]['score_ci']['lower'] = 1-upp\n",
    "                results[method]['score_ci']['upper'] = 1-low\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95419f8-1290-42ea-9931-61cff7ac37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "truthful_res = get_results_single(base_path_truth, flip_t_f=False,\n",
    "                                 model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a1ad26-5cea-4487-b6fb-1e530074b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_res = get_results_single(base_path_trivia, flip_t_f=False,\n",
    "                               model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b35202b-8383-490e-ab30-a68260520ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_res = get_results_single(base_path_safety, flip_t_f=False, \n",
    "                                model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75efd0e-6c6e-4213-999e-ee78d5b59547",
   "metadata": {},
   "outputs": [],
   "source": [
    "jbb_res = get_results_single(base_path_jbb, flip_t_f=False,\n",
    "                            model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29719f34-2d26-4a81-ae0c-ebc64e3469a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_res = get_results_single(base_path_toxicity, flip_t_f=True,\n",
    "                                 model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "792514f3-adea-4ea2-a3eb-80089aabdea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, res_dict, method, subcase=None):\n",
    "    if subcase is None:\n",
    "        subcase = data\n",
    "    pos_total = res_dict[method]['true']\n",
    "    neg_total = res_dict[method]['false']\n",
    "    uns_total = res_dict[method]['unsure']\n",
    "    n_total = res_dict[method]['total']\n",
    "    d = {'Data': data,\n",
    "           'Subcase': subcase,\n",
    "           'Method': method,\n",
    "           'Postives': pos_total,\n",
    "           'Negatives': neg_total,\n",
    "           'Unsure': uns_total,\n",
    "           'Total': n_total,\n",
    "           'Success rate': res_dict[method]['score'],\n",
    "           'Score CI - Lower': res_dict[method]['score_ci']['lower'],\n",
    "           'Score CI - Upper': res_dict[method]['score_ci']['upper'],\n",
    "           'Average score': res_dict[method]['score'],\n",
    "           'Fluency': res_dict[method]['fluency'],\n",
    "           'Fluency CI - Lower': res_dict[method]['fluency_ci']['lower'],\n",
    "           'Fluency CI - Upper': res_dict[method]['fluency_ci']['upper'],\n",
    "        }\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c795f9b-3e16-4488-b11f-3348191dafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_list_all = []\n",
    "\n",
    "data = 'Emotion'\n",
    "for emotion in emo_results.keys():\n",
    "    for method in emo_results[emotion].keys():\n",
    "        d = process_data(data, emo_results[emotion], method, emotion)\n",
    "        rates_list_all.append(d)\n",
    "\n",
    "data = 'AI Persona'\n",
    "for b in risk_results.keys():\n",
    "    for method in risk_results[b].keys():\n",
    "        d = process_data(data, risk_results[b], method, b)\n",
    "        rates_list_all.append(d)\n",
    "\n",
    "data = 'TruthfulQA'\n",
    "for method in truthful_res.keys():\n",
    "    d = process_data(data, truthful_res, method)\n",
    "    rates_list_all.append(d)\n",
    "\n",
    "data = 'AdvBench'\n",
    "for method in safety_res.keys():\n",
    "    d = process_data(data, safety_res, method)\n",
    "    rates_list_all.append(d)\n",
    "\n",
    "data = 'JailbreakBench'\n",
    "for method in jbb_res.keys():\n",
    "    d = process_data(data, jbb_res, method)\n",
    "    rates_list_all.append(d)\n",
    "\n",
    "data = 'TriviaQA'\n",
    "for method in trivia_res.keys():\n",
    "    d = process_data(data, trivia_res, method)\n",
    "    rates_list_all.append(d)\n",
    "    \n",
    "data = 'Toxicity'\n",
    "for method in toxicity_res.keys():\n",
    "    d = process_data(data, toxicity_res, method)\n",
    "    rates_list_all.append(d)\n",
    "\n",
    "rates_all_df = pd.DataFrame(rates_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78195787-af32-4e2b-916c-f0e72d7f2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_map = {'baseline': 'Default',\n",
    "              'linear': 'Linear',\n",
    "              'mean': 'DiffMean',\n",
    "              'pca': 'PCAct',\n",
    "              'repe': 'PCDiff',\n",
    "              'random': 'Random',\n",
    "              'refusal': 'Projection',\n",
    "              'prompt': 'Prompt-only',\n",
    "              'prompt-attention': 'InstA-Boost'\n",
    "             }\n",
    "rates_all_df['Method'] = rates_all_df['Method'].map(method_map)\n",
    "rates_all_df.to_csv(f'../results/steering_results_{model}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bdb7b-dd2a-48e9-b9d0-ad5148fa6877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
